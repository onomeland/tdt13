{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da8485fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /cluster/home/olavanom/.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sentence-transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /cluster/home/olavanom/.local/lib/python3.9/site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: scipy in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sentence-transformers) (4.29.1)\n",
      "Requirement already satisfied: nltk in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: scikit-learn in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: tqdm in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: sentencepiece in /cluster/home/olavanom/.local/lib/python3.9/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: numpy in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: filelock in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: fsspec in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: networkx in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: sympy in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: lit in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (15.0.7)\n",
      "Requirement already satisfied: cmake in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: click in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==2.0.1+cu118 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: jinja2 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch==2.0.1+cu118) (2.11.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch==2.0.1+cu118) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch==2.0.1+cu118) (4.5.0)\n",
      "Requirement already satisfied: networkx in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch==2.0.1+cu118) (2.7.1)\n",
      "Requirement already satisfied: filelock in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch==2.0.1+cu118) (3.6.0)\n",
      "Requirement already satisfied: sympy in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from torch==2.0.1+cu118) (1.10.1)\n",
      "Requirement already satisfied: cmake in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.25.0)\n",
      "Requirement already satisfied: lit in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.1+cu118) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from jinja2->torch==2.0.1+cu118) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from sympy->torch==2.0.1+cu118) (1.2.1)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
      "\u001b[K     |███████████████████▋            | 300.2 MB 174.0 MB/s eta 0:00:02  |█▉                              | 28.0 MB 3.4 MB/s eta 0:02:15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 489.8 MB 112.3 MB/s eta 0:00:01\u001b[K     |████████████████████████████████| 489.8 MB 18 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.5 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (1.24.3)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 5.8 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[K     |████████████████████████████████| 440 kB 141.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.9 MB 152.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (61.2.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 136.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting ml-dtypes==0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 133.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 34.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (1.54.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 158.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (4.5.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 4.4 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: urllib3<2.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, ml-dtypes, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-23.5.26 gast-0.5.4 google-pasta-0.2.0 keras-2.14.0 libclang-16.0.6 ml-dtypes-0.2.0 opt-einsum-3.3.0 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "!pip install torch==2.0.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install tensorflow\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b1a3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import re\n",
    "import gzip\n",
    "import torch\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "\n",
    "from ast import literal_eval\n",
    "from itertools import zip_longest\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer, util, models\n",
    "from tensorflow import keras\n",
    "from torch.cuda import is_available\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, mean_absolute_error, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309deec3",
   "metadata": {},
   "source": [
    "## Extract dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478995b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df_0 = getDF('Sports_and_Outdoors_5.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9b6d0",
   "metadata": {},
   "source": [
    "## Clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c21b05f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>What a spectacular tutu! Very slimming.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>What the heck? Is this a tutu for nuns? I know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Exactly what we were looking for!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I used this skirt for a Halloween costume and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>This is thick enough that you can't see throug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review\n",
       "0     5.0            What a spectacular tutu! Very slimming.\n",
       "1     1.0  What the heck? Is this a tutu for nuns? I know...\n",
       "2     5.0                  Exactly what we were looking for!\n",
       "3     5.0  I used this skirt for a Halloween costume and ...\n",
       "4     4.0  This is thick enough that you can't see throug..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_0[[\"overall\", \"reviewText\"]]\n",
    "df = df.rename(columns={\"overall\": \"rating\", \"reviewText\": \"review\"})\n",
    "df[\"review\"] = df[\"review\"].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f7a52",
   "metadata": {},
   "source": [
    "#### Observe that the majority of votes are 5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14bbd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5.0    1921398\n",
       "4.0     495533\n",
       "3.0     210215\n",
       "1.0     111157\n",
       "2.0     101637\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817140a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Rating')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cplot = sns.countplot(data=df_0[[\"overall\", \"reviewText\"]], x=\"overall\")\n",
    "cplot.set_xlabel(\"Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5596d",
   "metadata": {},
   "source": [
    "# SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3debcf4",
   "metadata": {},
   "source": [
    "#### Balance dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "888ef37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating_count = df['rating'].value_counts().min()\n",
    "\n",
    "balanced_dfs = []\n",
    "\n",
    "for rating in df['rating'].unique():\n",
    "    rating_df = df[df['rating'] == rating]\n",
    "    selected_rows = rating_df.sample(n=min_rating_count, random_state=1)\n",
    "    balanced_dfs.append(selected_rows)\n",
    "\n",
    "balanced_df = pd.concat(balanced_dfs)\n",
    "df = balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a12a4",
   "metadata": {},
   "source": [
    "#### Add SBERT encodings of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb043aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Model is running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508185/508185 [1:11:50<00:00, 117.89it/s]\n"
     ]
    }
   ],
   "source": [
    "sbert_model = SentenceTransformer(model_name_or_path='paraphrase-MiniLM-L12-v2')\n",
    "\n",
    "sbert_model.max_seq_length = 512\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    sbert_model.to('cuda')\n",
    "    print(\"Using GPU\")\n",
    "    print(f\"Model is running on device: {next(sbert_model.parameters()).device}\")\n",
    "\n",
    "encoded_reviews = []\n",
    "\n",
    "def encode_text_with_progress(text):\n",
    "    encoding = sbert_model.encode(text)\n",
    "    return encoding\n",
    "\n",
    "for text in tqdm(df['review']):\n",
    "    encoded_reviews.append(encode_text_with_progress(text).flatten())\n",
    "\n",
    "df['encoded_review'] = encoded_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9febcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Model is running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508185/508185 [1:06:27<00:00, 127.44it/s]\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    bert_model.to('cuda')\n",
    "    print(\"Using GPU\")\n",
    "    print(f\"Model is running on device: {next(bert_model.parameters()).device}\")\n",
    "\n",
    "encoded_reviews_bert = []\n",
    "\n",
    "def encode_text_with_progress_bert(text):\n",
    "    tokens = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**tokens)\n",
    "\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    pooled_embedding = torch.mean(embeddings, dim=1)\n",
    "\n",
    "    return pooled_embedding\n",
    "\n",
    "for text in tqdm(df['review']):\n",
    "    encoding = encode_text_with_progress_bert(text).flatten().cpu().numpy()\n",
    "    encoded_reviews_bert.append(encoding)\n",
    "\n",
    "max_len = max(len(enc) for enc in encoded_reviews_bert)\n",
    "padded_encodings = [np.pad(enc, (0, max_len - len(enc))) for enc in encoded_reviews_bert]\n",
    "\n",
    "df[\"encoded_review_bert\"] = padded_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3db5ae28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec10f79f7c68410aa6eab24c5c54497d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bb67d315aa45f7a82a10287f494e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77959071643425b95136cbb1438203f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be026546bf442918839a609e74024fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Model is running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508185/508185 [1:02:30<00:00, 135.51it/s]\n"
     ]
    }
   ],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    roberta_model.to('cuda')\n",
    "    print(\"Using GPU\")\n",
    "    print(f\"Model is running on device: {next(roberta_model.parameters()).device}\")\n",
    "\n",
    "encoded_reviews_roberta = []\n",
    "\n",
    "def encode_text_with_progress_roberta(text):\n",
    "    tokens = roberta_tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        tokens = {key: val.to('cuda') for key, val in tokens.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = roberta_model(**tokens)\n",
    "\n",
    "    encoding = output.last_hidden_state.mean(dim=1).flatten()\n",
    "    return encoding.cpu().numpy()\n",
    "\n",
    "for text in tqdm(df['review']):\n",
    "    encoded_reviews_roberta.append(encode_text_with_progress_roberta(text))\n",
    "\n",
    "df['encoded_review_roberta'] = encoded_reviews_roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee38b32",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d98d78",
   "metadata": {},
   "source": [
    "# 5-way classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37e1b8",
   "metadata": {},
   "source": [
    "## Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2522725f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5.]), array([81350, 81283, 81264, 81385, 81266]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sbert, X_test_sbert, y_train, y_test = train_test_split(np.array(df[\"encoded_review_sbert\"].values.tolist()), df[\"rating\"].values, test_size=0.2, random_state=SEED)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a94974bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5.]), array([81350, 81283, 81264, 81385, 81266]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(df[\"encoded_review_bert\"].values.tolist(), df[\"rating\"].values, test_size=0.2, random_state=SEED)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "50b31f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5.]), array([81350, 81283, 81264, 81385, 81266]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_roberta, X_test_roberta, y_train, y_test = train_test_split(df[\"encoded_review_roberta\"].values.tolist(), df[\"rating\"].values, test_size=0.2, random_state=SEED)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31fdd7",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "82045763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.381\n",
      "Average difference between predicted rating and ground truth: 1.009\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "decision_tree.fit(X_train_sbert, y_train)\n",
    "y_pred = decision_tree.predict(X_test_sbert)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1124e6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.386\n",
      "Average difference between predicted rating and ground truth: 1.016\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "decision_tree.fit(X_train_bert, y_train)\n",
    "y_pred = decision_tree.predict(X_test_bert)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "def84f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.395\n",
      "Average difference between predicted rating and ground truth: 0.982\n"
     ]
    }
   ],
   "source": [
    "# ROBERTA\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "decision_tree.fit(X_train_roberta, y_train)\n",
    "y_pred = decision_tree.predict(X_test_roberta)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b56387",
   "metadata": {},
   "source": [
    "#### Cross validate decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f1f2ac9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Test Accuracy with Best Model: 0.381\n",
      "Average difference between predicted rating and ground truth: 0.925\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_sbert, y_train)\n",
    "\n",
    "best_decision_tree = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_decision_tree.predict(X_test_sbert)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(f\"Test Accuracy with Best Model: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "46324d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Test Accuracy with Best Model: 0.385\n",
      "Average difference between predicted rating and ground truth: 0.962\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_bert, y_train)\n",
    "\n",
    "best_decision_tree = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_decision_tree.predict(X_test_bert)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(f\"Test Accuracy with Best Model: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9982d153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Test Accuracy with Best Model: 0.398\n",
      "Average difference between predicted rating and ground truth: 0.918\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_roberta, y_train)\n",
    "\n",
    "best_decision_tree = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_decision_tree.predict(X_test_roberta)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(f\"Test Accuracy with Best Model: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47a756",
   "metadata": {},
   "source": [
    "## SVC (c for discrete classification, m for continous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d1651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.496\n",
      "Average difference between predicted rating and ground truth: 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "linear_svc_classifier = LinearSVC(random_state=SEED)\n",
    "linear_svc_classifier.fit(X_train_sbert, y_train)\n",
    "y_pred = linear_svc_classifier.predict(X_test_sbert)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c8c35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.516\n",
      "Average difference between predicted rating and ground truth: 0.655\n"
     ]
    }
   ],
   "source": [
    "#BERT\n",
    "\n",
    "linear_svc_classifier = LinearSVC(random_state=SEED)\n",
    "linear_svc_classifier.fit(X_train_bert, y_train)\n",
    "y_pred = linear_svc_classifier.predict(X_test_bert)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6b75cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.541\n",
      "Average difference between predicted rating and ground truth: 0.595\n"
     ]
    }
   ],
   "source": [
    "#ROBERTA\n",
    "\n",
    "linear_svc_classifier = LinearSVC(random_state=SEED)\n",
    "linear_svc_classifier.fit(X_train_roberta, y_train)\n",
    "y_pred = linear_svc_classifier.predict(X_test_roberta)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33abf23",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e15bb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 11:28:03.940266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 77855 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:48:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 11:28:03.987034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78407 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:8a:00.0, compute capability: 8.0\n",
      "2023-11-13 11:28:03.988129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 78407 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c0:00.0, compute capability: 8.0\n",
      "2023-11-13 11:28:03.989111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 78407 MB memory:  -> device: 3, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c1:00.0, compute capability: 8.0\n",
      "2023-11-13 11:28:11.722179: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-13 11:28:12.484572: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558dd2648f10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-13 11:28:12.484606: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-13 11:28:12.484612: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-13 11:28:12.484616: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-13 11:28:12.484620: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-13 11:28:12.794165: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-13 11:28:13.373971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-13 11:28:14.018950: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12705/12705 [==============================] - 31s 2ms/step - loss: 1.1341 - accuracy: 0.4985 - val_loss: 1.1105 - val_accuracy: 0.5096\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0979 - accuracy: 0.5158 - val_loss: 1.1013 - val_accuracy: 0.5127\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0827 - accuracy: 0.5224 - val_loss: 1.0962 - val_accuracy: 0.5164\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0722 - accuracy: 0.5280 - val_loss: 1.0994 - val_accuracy: 0.5153\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0636 - accuracy: 0.5320 - val_loss: 1.0981 - val_accuracy: 0.5170\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0569 - accuracy: 0.5360 - val_loss: 1.0972 - val_accuracy: 0.5151\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0518 - accuracy: 0.5383 - val_loss: 1.0991 - val_accuracy: 0.5174\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0466 - accuracy: 0.5412 - val_loss: 1.1014 - val_accuracy: 0.5167\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0425 - accuracy: 0.5429 - val_loss: 1.0973 - val_accuracy: 0.5168\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0389 - accuracy: 0.5447 - val_loss: 1.0988 - val_accuracy: 0.5174\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.0988 - accuracy: 0.5174\n",
      "Test loss: 1.0988471508026123, Test accuracy: 0.5174099802970886\n",
      "3177/3177 [==============================] - 3s 824us/step\n",
      "Average difference between predicted rating and ground truth: 0.624\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train_sbert)\n",
    "X_test = np.array(X_test_sbert)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train - 1, num_classes=5)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test - 1, num_classes=5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e32f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1328 - accuracy: 0.4969 - val_loss: 1.1068 - val_accuracy: 0.5102\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0920 - accuracy: 0.5168 - val_loss: 1.0961 - val_accuracy: 0.5160\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0719 - accuracy: 0.5261 - val_loss: 1.0890 - val_accuracy: 0.5186\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0547 - accuracy: 0.5341 - val_loss: 1.0915 - val_accuracy: 0.5194\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0410 - accuracy: 0.5400 - val_loss: 1.0939 - val_accuracy: 0.5190\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0281 - accuracy: 0.5464 - val_loss: 1.0978 - val_accuracy: 0.5204\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0159 - accuracy: 0.5517 - val_loss: 1.0958 - val_accuracy: 0.5220\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0049 - accuracy: 0.5564 - val_loss: 1.1014 - val_accuracy: 0.5203\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 0.9943 - accuracy: 0.5618 - val_loss: 1.1072 - val_accuracy: 0.5184\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 0.9847 - accuracy: 0.5657 - val_loss: 1.1119 - val_accuracy: 0.5202\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.1119 - accuracy: 0.5202\n",
      "Test loss: 1.1119333505630493, Test accuracy: 0.5202435851097107\n",
      "3177/3177 [==============================] - 3s 881us/step\n",
      "Average difference between predicted rating and ground truth: 0.617\n"
     ]
    }
   ],
   "source": [
    "# Deep NN\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e02c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 33s 2ms/step - loss: 1.2180 - accuracy: 0.4621 - val_loss: 1.1392 - val_accuracy: 0.4976\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1806 - accuracy: 0.4791 - val_loss: 1.1357 - val_accuracy: 0.4970\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1737 - accuracy: 0.4824 - val_loss: 1.1317 - val_accuracy: 0.5013\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1669 - accuracy: 0.4855 - val_loss: 1.1271 - val_accuracy: 0.4991\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1629 - accuracy: 0.4883 - val_loss: 1.1210 - val_accuracy: 0.5027\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1611 - accuracy: 0.4882 - val_loss: 1.1241 - val_accuracy: 0.5072\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1570 - accuracy: 0.4902 - val_loss: 1.1173 - val_accuracy: 0.5045\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1565 - accuracy: 0.4910 - val_loss: 1.1169 - val_accuracy: 0.5043\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1548 - accuracy: 0.4909 - val_loss: 1.1183 - val_accuracy: 0.5097\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1522 - accuracy: 0.4929 - val_loss: 1.1128 - val_accuracy: 0.5098\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.1128 - accuracy: 0.5098\n",
      "Test loss: 1.1127856969833374, Test accuracy: 0.5097553133964539\n",
      "3177/3177 [==============================] - 3s 896us/step\n",
      "Average difference between predicted rating and ground truth: 0.624\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c34931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 180s 14ms/step - loss: 1.6097 - accuracy: 0.1992 - val_loss: 1.6095 - val_accuracy: 0.1993\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 175s 14ms/step - loss: 1.6096 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.1996\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 173s 14ms/step - loss: 1.6095 - accuracy: 0.2003 - val_loss: 1.6096 - val_accuracy: 0.2004\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 175s 14ms/step - loss: 1.6095 - accuracy: 0.2008 - val_loss: 1.6096 - val_accuracy: 0.2004\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 175s 14ms/step - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6094 - val_accuracy: 0.1996\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 175s 14ms/step - loss: 1.6095 - accuracy: 0.2000 - val_loss: 1.6097 - val_accuracy: 0.1996\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 176s 14ms/step - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6096 - val_accuracy: 0.1992\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 176s 14ms/step - loss: 1.6095 - accuracy: 0.2009 - val_loss: 1.6095 - val_accuracy: 0.2004\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 176s 14ms/step - loss: 1.6095 - accuracy: 0.1998 - val_loss: 1.6096 - val_accuracy: 0.1996\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 173s 14ms/step - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6095 - val_accuracy: 0.2004\n",
      "3177/3177 [==============================] - 19s 6ms/step - loss: 1.6095 - accuracy: 0.2004\n",
      "Test loss: 1.6094820499420166, Test accuracy: 0.20042897760868073\n",
      "3177/3177 [==============================] - 16s 5ms/step\n",
      "Average difference between predicted rating and ground truth: 1.999\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(input_dim=1000, output_dim=64))\n",
    "rnn_model.add(LSTM(128))\n",
    "rnn_model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "rnn_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "rnn_model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = rnn_model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = rnn_model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfbcdf7",
   "metadata": {},
   "source": [
    "## BERT NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b956a1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:55:01.560496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 77543 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:48:00.0, compute capability: 8.0\n",
      "2023-11-10 12:55:01.606642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78407 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:8a:00.0, compute capability: 8.0\n",
      "2023-11-10 12:55:01.607849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 78407 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c0:00.0, compute capability: 8.0\n",
      "2023-11-10 12:55:01.608891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 78407 MB memory:  -> device: 3, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:55:11.279643: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-10 12:55:12.089136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bbdd388e50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-10 12:55:12.089209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-10 12:55:12.089215: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-10 12:55:12.089218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-10 12:55:12.089222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-10 12:55:12.415133: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-10 12:55:12.943346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-10 12:55:13.444512: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12705/12705 [==============================] - 32s 2ms/step - loss: 1.1202 - accuracy: 0.5047 - val_loss: 1.0989 - val_accuracy: 0.5135\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0851 - accuracy: 0.5195 - val_loss: 1.0813 - val_accuracy: 0.5220\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0727 - accuracy: 0.5258 - val_loss: 1.0822 - val_accuracy: 0.5206\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0643 - accuracy: 0.5305 - val_loss: 1.0676 - val_accuracy: 0.5291\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0579 - accuracy: 0.5329 - val_loss: 1.0682 - val_accuracy: 0.5277\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0529 - accuracy: 0.5352 - val_loss: 1.0648 - val_accuracy: 0.5283\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0485 - accuracy: 0.5366 - val_loss: 1.0765 - val_accuracy: 0.5243\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0450 - accuracy: 0.5381 - val_loss: 1.0757 - val_accuracy: 0.5254\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0413 - accuracy: 0.5406 - val_loss: 1.0646 - val_accuracy: 0.5315\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0389 - accuracy: 0.5409 - val_loss: 1.0600 - val_accuracy: 0.5320\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.0600 - accuracy: 0.5320\n",
      "Test loss: 1.0599929094314575, Test accuracy: 0.5320109724998474\n",
      "3177/3177 [==============================] - 3s 878us/step\n",
      "Average difference between predicted rating and ground truth: 0.586\n"
     ]
    }
   ],
   "source": [
    "X_train_bert = np.array(X_train_bert)\n",
    "X_test_bert = np.array(X_test_bert)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train - 1, num_classes=5)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test - 1, num_classes=5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train_bert.shape[1],)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_bert, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test_bert, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_bert, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test_bert)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0344c998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 31s 2ms/step - loss: 1.1223 - accuracy: 0.5028 - val_loss: 1.1004 - val_accuracy: 0.5155\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0844 - accuracy: 0.5201 - val_loss: 1.0914 - val_accuracy: 0.5163\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0704 - accuracy: 0.5271 - val_loss: 1.0681 - val_accuracy: 0.5304\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0595 - accuracy: 0.5321 - val_loss: 1.0724 - val_accuracy: 0.5274\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0514 - accuracy: 0.5355 - val_loss: 1.0640 - val_accuracy: 0.5316\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0442 - accuracy: 0.5379 - val_loss: 1.0653 - val_accuracy: 0.5302\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0381 - accuracy: 0.5407 - val_loss: 1.0586 - val_accuracy: 0.5340\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0331 - accuracy: 0.5429 - val_loss: 1.0593 - val_accuracy: 0.5342\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0273 - accuracy: 0.5458 - val_loss: 1.0707 - val_accuracy: 0.5281\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0226 - accuracy: 0.5478 - val_loss: 1.0693 - val_accuracy: 0.5304\n",
      "3177/3177 [==============================] - 5s 1ms/step - loss: 1.0693 - accuracy: 0.5304\n",
      "Test loss: 1.0693244934082031, Test accuracy: 0.5303974151611328\n",
      "3177/3177 [==============================] - 3s 959us/step\n",
      "Average difference between predicted rating and ground truth: 0.59\n"
     ]
    }
   ],
   "source": [
    "X_train_bert = np.array(X_train_bert)\n",
    "X_test_bert = np.array(X_test_bert)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train - 1, num_classes=5)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test - 1, num_classes=5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train_bert.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_bert, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test_bert, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_bert, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test_bert)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298144d2",
   "metadata": {},
   "source": [
    "## ROBERTA NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5414266d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 33s 2ms/step - loss: 1.0558 - accuracy: 0.5328 - val_loss: 1.0302 - val_accuracy: 0.5438\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0171 - accuracy: 0.5506 - val_loss: 1.0416 - val_accuracy: 0.5405\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0039 - accuracy: 0.5560 - val_loss: 1.0085 - val_accuracy: 0.5549\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9953 - accuracy: 0.5600 - val_loss: 1.0068 - val_accuracy: 0.5555\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9878 - accuracy: 0.5633 - val_loss: 1.0062 - val_accuracy: 0.5553\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9818 - accuracy: 0.5665 - val_loss: 1.0014 - val_accuracy: 0.5574\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9769 - accuracy: 0.5681 - val_loss: 1.0029 - val_accuracy: 0.5572\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9726 - accuracy: 0.5708 - val_loss: 1.0006 - val_accuracy: 0.5542\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9683 - accuracy: 0.5722 - val_loss: 1.0010 - val_accuracy: 0.5570\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9644 - accuracy: 0.5744 - val_loss: 1.0031 - val_accuracy: 0.5567\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.0031 - accuracy: 0.5567\n",
      "Test loss: 1.0031391382217407, Test accuracy: 0.5567460656166077\n",
      "3177/3177 [==============================] - 3s 853us/step\n",
      "Average difference between predicted rating and ground truth: 0.541\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train_roberta)\n",
    "X_test = np.array(X_test_roberta)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train - 1, num_classes=5)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test - 1, num_classes=5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdf5c257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.0542 - accuracy: 0.5327 - val_loss: 1.0243 - val_accuracy: 0.5470\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0169 - accuracy: 0.5507 - val_loss: 1.0134 - val_accuracy: 0.5522\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0018 - accuracy: 0.5572 - val_loss: 1.0115 - val_accuracy: 0.5526\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9909 - accuracy: 0.5618 - val_loss: 1.0023 - val_accuracy: 0.5552\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9822 - accuracy: 0.5646 - val_loss: 1.0049 - val_accuracy: 0.5568\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9747 - accuracy: 0.5695 - val_loss: 0.9972 - val_accuracy: 0.5581\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9678 - accuracy: 0.5715 - val_loss: 1.0078 - val_accuracy: 0.5550\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9610 - accuracy: 0.5747 - val_loss: 0.9949 - val_accuracy: 0.5613\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9548 - accuracy: 0.5772 - val_loss: 1.0280 - val_accuracy: 0.5508\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9486 - accuracy: 0.5805 - val_loss: 1.0001 - val_accuracy: 0.5596\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.0001 - accuracy: 0.5596\n",
      "Test loss: 1.0000765323638916, Test accuracy: 0.5595796704292297\n",
      "3177/3177 [==============================] - 3s 925us/step\n",
      "Average difference between predicted rating and ground truth: 0.537\n"
     ]
    }
   ],
   "source": [
    "# Deep NN\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a4ed1",
   "metadata": {},
   "source": [
    "# Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373e01d",
   "metadata": {},
   "source": [
    "#### Make 1&2 star ratings negative and 4&5 star ratings positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d85f06d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2410528/1005697633.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[\"positive\"] = (df2[\"rating\"] > 3).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>encoded_review_sbert</th>\n",
       "      <th>encoded_review_roberta</th>\n",
       "      <th>encoded_review_bert</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>830792</th>\n",
       "      <td>5.0</td>\n",
       "      <td>lazer nice but worth having the grip perfect</td>\n",
       "      <td>[-0.1466909, -0.12516333, -0.5601697, -0.04356...</td>\n",
       "      <td>[-0.062008798, 0.18042147, -0.06070903, -0.032...</td>\n",
       "      <td>[-0.123875156, -0.24859346, 0.24571559, 0.2377...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850653</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I just received my UTG pack yesterday, and aft...</td>\n",
       "      <td>[-0.2469892, 0.42250115, -0.17435247, -0.09039...</td>\n",
       "      <td>[-0.026691116, 0.20569725, 0.0012298374, -0.05...</td>\n",
       "      <td>[-0.1667779, -0.033920705, 0.22260371, 0.09758...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626724</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Does not leak (as long as you put the cap on r...</td>\n",
       "      <td>[-0.24478982, 0.17316727, -0.12371678, -0.4412...</td>\n",
       "      <td>[0.001923264, 0.039070137, 0.00090832263, -0.0...</td>\n",
       "      <td>[0.14108594, -0.23224497, 0.39572367, -0.20799...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367874</th>\n",
       "      <td>5.0</td>\n",
       "      <td>bright light works great for my college son. J...</td>\n",
       "      <td>[0.020240288, -0.10725535, 0.2922491, 0.305173...</td>\n",
       "      <td>[-0.002267656, 0.13629214, 0.008082978, -0.117...</td>\n",
       "      <td>[0.3685369, 0.085767716, 0.44435415, -0.103456...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769707</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This is my 4th top for my 40oz fifty-fifty bot...</td>\n",
       "      <td>[-0.07240746, -0.0045981924, 0.05199444, -0.02...</td>\n",
       "      <td>[-0.038737267, 0.11030901, -0.031557377, -0.13...</td>\n",
       "      <td>[-0.17748058, 0.009539982, 0.44630298, 0.00836...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446259</th>\n",
       "      <td>2.0</td>\n",
       "      <td>These are pretty cheap.  The big ones are okay...</td>\n",
       "      <td>[-0.048299145, 0.12944467, 0.31336844, -0.0091...</td>\n",
       "      <td>[0.01072515, 0.1995503, 0.031587593, -0.195092...</td>\n",
       "      <td>[0.10510927, 0.042450733, 0.13578537, 0.196205...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759763</th>\n",
       "      <td>2.0</td>\n",
       "      <td>to hard to use. not worth the money</td>\n",
       "      <td>[-0.37008867, -0.29714772, -0.24915065, 0.1546...</td>\n",
       "      <td>[-0.08465307, 0.04587426, -0.008179868, -0.035...</td>\n",
       "      <td>[-0.04212603, -0.25559938, 0.069136925, 0.2609...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157566</th>\n",
       "      <td>2.0</td>\n",
       "      <td>This sword display would be ok for the price, ...</td>\n",
       "      <td>[-0.118137226, 0.19106281, 0.012811152, -0.007...</td>\n",
       "      <td>[-0.036841143, 0.123045094, 0.056401867, -0.00...</td>\n",
       "      <td>[-0.22836113, -0.08283205, 0.21313386, 0.09037...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211288</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Too wide in all directions.</td>\n",
       "      <td>[0.6949, -0.16437449, 0.18026513, 0.17394236, ...</td>\n",
       "      <td>[-0.0057778587, 0.029149929, 0.06683141, -0.07...</td>\n",
       "      <td>[-0.38585982, -0.19612728, 0.28427878, -0.1135...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771815</th>\n",
       "      <td>2.0</td>\n",
       "      <td>They aren't consistent sizes or weights at all.</td>\n",
       "      <td>[-0.2646532, -0.053607605, 0.3164193, 0.044488...</td>\n",
       "      <td>[0.019586608, 0.10958537, -0.050748657, -0.061...</td>\n",
       "      <td>[0.3365965, 0.20294352, 0.15622438, 0.30686295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406548 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  \\\n",
       "830792      5.0       lazer nice but worth having the grip perfect   \n",
       "850653      5.0  I just received my UTG pack yesterday, and aft...   \n",
       "1626724     5.0  Does not leak (as long as you put the cap on r...   \n",
       "1367874     5.0  bright light works great for my college son. J...   \n",
       "1769707     5.0  This is my 4th top for my 40oz fifty-fifty bot...   \n",
       "...         ...                                                ...   \n",
       "1446259     2.0  These are pretty cheap.  The big ones are okay...   \n",
       "2759763     2.0                to hard to use. not worth the money   \n",
       "157566      2.0  This sword display would be ok for the price, ...   \n",
       "2211288     2.0                        Too wide in all directions.   \n",
       "2771815     2.0    They aren't consistent sizes or weights at all.   \n",
       "\n",
       "                                      encoded_review_sbert  \\\n",
       "830792   [-0.1466909, -0.12516333, -0.5601697, -0.04356...   \n",
       "850653   [-0.2469892, 0.42250115, -0.17435247, -0.09039...   \n",
       "1626724  [-0.24478982, 0.17316727, -0.12371678, -0.4412...   \n",
       "1367874  [0.020240288, -0.10725535, 0.2922491, 0.305173...   \n",
       "1769707  [-0.07240746, -0.0045981924, 0.05199444, -0.02...   \n",
       "...                                                    ...   \n",
       "1446259  [-0.048299145, 0.12944467, 0.31336844, -0.0091...   \n",
       "2759763  [-0.37008867, -0.29714772, -0.24915065, 0.1546...   \n",
       "157566   [-0.118137226, 0.19106281, 0.012811152, -0.007...   \n",
       "2211288  [0.6949, -0.16437449, 0.18026513, 0.17394236, ...   \n",
       "2771815  [-0.2646532, -0.053607605, 0.3164193, 0.044488...   \n",
       "\n",
       "                                    encoded_review_roberta  \\\n",
       "830792   [-0.062008798, 0.18042147, -0.06070903, -0.032...   \n",
       "850653   [-0.026691116, 0.20569725, 0.0012298374, -0.05...   \n",
       "1626724  [0.001923264, 0.039070137, 0.00090832263, -0.0...   \n",
       "1367874  [-0.002267656, 0.13629214, 0.008082978, -0.117...   \n",
       "1769707  [-0.038737267, 0.11030901, -0.031557377, -0.13...   \n",
       "...                                                    ...   \n",
       "1446259  [0.01072515, 0.1995503, 0.031587593, -0.195092...   \n",
       "2759763  [-0.08465307, 0.04587426, -0.008179868, -0.035...   \n",
       "157566   [-0.036841143, 0.123045094, 0.056401867, -0.00...   \n",
       "2211288  [-0.0057778587, 0.029149929, 0.06683141, -0.07...   \n",
       "2771815  [0.019586608, 0.10958537, -0.050748657, -0.061...   \n",
       "\n",
       "                                       encoded_review_bert  positive  \n",
       "830792   [-0.123875156, -0.24859346, 0.24571559, 0.2377...         1  \n",
       "850653   [-0.1667779, -0.033920705, 0.22260371, 0.09758...         1  \n",
       "1626724  [0.14108594, -0.23224497, 0.39572367, -0.20799...         1  \n",
       "1367874  [0.3685369, 0.085767716, 0.44435415, -0.103456...         1  \n",
       "1769707  [-0.17748058, 0.009539982, 0.44630298, 0.00836...         1  \n",
       "...                                                    ...       ...  \n",
       "1446259  [0.10510927, 0.042450733, 0.13578537, 0.196205...         0  \n",
       "2759763  [-0.04212603, -0.25559938, 0.069136925, 0.2609...         0  \n",
       "157566   [-0.22836113, -0.08283205, 0.21313386, 0.09037...         0  \n",
       "2211288  [-0.38585982, -0.19612728, 0.28427878, -0.1135...         0  \n",
       "2771815  [0.3365965, 0.20294352, 0.15622438, 0.30686295...         0  \n",
       "\n",
       "[406548 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df[\"rating\"] != 3]\n",
    "df2[\"positive\"] = (df2[\"rating\"] > 3).astype(int)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bfecf3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sbert, X_test_sbert, y_train, y_test = train_test_split(np.array(df2[\"encoded_review_sbert\"].values.tolist()), df2[\"positive\"].values, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "842641bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(np.array(df2[\"encoded_review_bert\"].values.tolist()), df2[\"positive\"].values, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9b1719a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_roberta, X_test_roberta, y_train, y_test = train_test_split(np.array(df2[\"encoded_review_roberta\"].values.tolist()), df2[\"positive\"].values, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b55fc24",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d704e08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 20}\n",
      "Accuracy: 0.88\n",
      "Precision: 0.885\n",
      "Recall: 0.873\n",
      "F1 Score: 0.879\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "param_grid = {\n",
    "    'C': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "logistic = LogisticRegression(random_state=SEED, max_iter=1000000)\n",
    "\n",
    "grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_sbert, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_logistic = grid_search.best_estimator_\n",
    "\n",
    "logistic_prediction = best_logistic.predict(X_test_sbert)\n",
    "\n",
    "accuracy_logistic = accuracy_score(y_test, logistic_prediction)\n",
    "precision_logistic = precision_score(y_test, logistic_prediction)\n",
    "recall_logistic = recall_score(y_test, logistic_prediction)\n",
    "f1_logistic = f1_score(y_test, logistic_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_logistic, 3)}\")\n",
    "print(f\"Precision: {round(precision_logistic, 3)}\")\n",
    "print(f\"Recall: {round(recall_logistic, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_logistic, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e4e2bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 15}\n",
      "Accuracy: 0.891\n",
      "Precision: 0.895\n",
      "Recall: 0.886\n",
      "F1 Score: 0.891\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "\n",
    "param_grid = {\n",
    "    'C': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "logistic = LogisticRegression(random_state=SEED, max_iter=1000000)\n",
    "\n",
    "grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_bert, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_logistic = grid_search.best_estimator_\n",
    "\n",
    "logistic_prediction = best_logistic.predict(X_test_bert)\n",
    "\n",
    "accuracy_logistic = accuracy_score(y_test, logistic_prediction)\n",
    "precision_logistic = precision_score(y_test, logistic_prediction)\n",
    "recall_logistic = recall_score(y_test, logistic_prediction)\n",
    "f1_logistic = f1_score(y_test, logistic_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_logistic, 3)}\")\n",
    "print(f\"Precision: {round(precision_logistic, 3)}\")\n",
    "print(f\"Recall: {round(recall_logistic, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_logistic, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "045317bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 25}\n",
      "Accuracy: 0.914\n",
      "Precision: 0.918\n",
      "Recall: 0.908\n",
      "F1 Score: 0.913\n"
     ]
    }
   ],
   "source": [
    "# ROBERTA\n",
    "\n",
    "param_grid = {\n",
    "    'C': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "logistic = LogisticRegression(random_state=SEED, max_iter=1000000)\n",
    "\n",
    "grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_roberta, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_logistic = grid_search.best_estimator_\n",
    "\n",
    "logistic_prediction = best_logistic.predict(X_test_roberta)\n",
    "\n",
    "accuracy_logistic = accuracy_score(y_test, logistic_prediction)\n",
    "precision_logistic = precision_score(y_test, logistic_prediction)\n",
    "recall_logistic = recall_score(y_test, logistic_prediction)\n",
    "f1_logistic = f1_score(y_test, logistic_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_logistic, 3)}\")\n",
    "print(f\"Precision: {round(precision_logistic, 3)}\")\n",
    "print(f\"Recall: {round(recall_logistic, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_logistic, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18412dbb",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722d6c18",
   "metadata": {},
   "source": [
    "#### Prepare random samples for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "820aef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "X_train_sbert_val = random.sample(X_train_sbert.tolist(), int(len(X_train_sbert.tolist()) * 0.05))\n",
    "X_test_sbert_val = random.sample(X_test_sbert.tolist(), int(len(X_test_sbert.tolist()) * 0.05))\n",
    "\n",
    "X_train_bert_val = random.sample(X_train_bert.tolist(), int(len(X_train_bert.tolist()) * 0.05))\n",
    "X_test_bert_val = random.sample(X_test_bert.tolist(), int(len(X_test_bert.tolist()) * 0.05))\n",
    "\n",
    "X_train_roberta_val = random.sample(X_train_roberta.tolist(), int(len(X_train_roberta.tolist()) * 0.05))\n",
    "X_test_roberta_val = random.sample(X_test_roberta.tolist(), int(len(X_test_roberta.tolist()) * 0.05))\n",
    "\n",
    "y_train_val = random.sample(y_train.tolist(), int(len(y_train.tolist()) * 0.05))\n",
    "y_test_val = random.sample(y_test.tolist(), int(len(y_test.tolist()) * 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "grid_search = GridSearchCV(random_forest, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfccd433",
   "metadata": {},
   "source": [
    "#### Cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "542854cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [20:07<5:01:58, 1207.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.502\n",
      "Precision: 0.498\n",
      "Recall: 0.627\n",
      "F1 Score: 0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_sbert_val, y_train_val)\n",
    "\n",
    "print(\"Best hyperparameters\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce43978a",
   "metadata": {},
   "source": [
    "#### Apply hyperparameters to the random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f29888fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.842\n",
      "Precision: 0.861\n",
      "Recall: 0.816\n",
      "F1 Score: 0.838\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=2, min_samples_split=2, random_state=SEED)\n",
    "random_forest.fit(X_train_sbert, y_train)\n",
    "\n",
    "random_forest_prediction = random_forest.predict(X_test_sbert)\n",
    "\n",
    "accuracy_random_forest = accuracy_score(y_test, random_forest_prediction)\n",
    "precision_random_forest = precision_score(y_test, random_forest_prediction)\n",
    "recall_random_forest = recall_score(y_test, random_forest_prediction)\n",
    "f1_random_forest = f1_score(y_test, random_forest_prediction)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_random_forest, 3)}\")\n",
    "print(f\"Precision: {round(precision_random_forest, 3)}\")\n",
    "print(f\"Recall: {round(recall_random_forest, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_random_forest, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bff866a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.851\n",
      "Precision: 0.88\n",
      "Recall: 0.812\n",
      "F1 Score: 0.845\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=2, min_samples_split=2, random_state=SEED)\n",
    "random_forest.fit(X_train_bert, y_train)\n",
    "\n",
    "random_forest_prediction = random_forest.predict(X_test_bert)\n",
    "\n",
    "accuracy_random_forest = accuracy_score(y_test, random_forest_prediction)\n",
    "precision_random_forest = precision_score(y_test, random_forest_prediction)\n",
    "recall_random_forest = recall_score(y_test, random_forest_prediction)\n",
    "f1_random_forest = f1_score(y_test, random_forest_prediction)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_random_forest, 3)}\")\n",
    "print(f\"Precision: {round(precision_random_forest, 3)}\")\n",
    "print(f\"Recall: {round(recall_random_forest, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_random_forest, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6246efdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.869\n",
      "Precision: 0.887\n",
      "Recall: 0.845\n",
      "F1 Score: 0.865\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa (with SBERT hyperparameters)\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=2, min_samples_split=2, random_state=SEED)\n",
    "random_forest.fit(X_train_roberta, y_train)\n",
    "\n",
    "random_forest_prediction = random_forest.predict(X_test_roberta)\n",
    "\n",
    "accuracy_random_forest = accuracy_score(y_test, random_forest_prediction)\n",
    "precision_random_forest = precision_score(y_test, random_forest_prediction)\n",
    "recall_random_forest = recall_score(y_test, random_forest_prediction)\n",
    "f1_random_forest = f1_score(y_test, random_forest_prediction)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_random_forest, 3)}\")\n",
    "print(f\"Precision: {round(precision_random_forest, 3)}\")\n",
    "print(f\"Recall: {round(recall_random_forest, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_random_forest, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1685e3",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c44041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819\n",
      "Precision: 0.821\n",
      "Recall: 0.816\n",
      "F1 Score: 0.818\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train_sbert, y_train)\n",
    "\n",
    "knn_predictions = knn.predict(X_test_sbert)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, knn_predictions)\n",
    "precision_knn = precision_score(y_test, knn_predictions)\n",
    "recall_knn = recall_score(y_test, knn_predictions)\n",
    "f1_knn = f1_score(y_test, knn_predictions)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40f2f0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 10}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'knn_forest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [127]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(knn_forest,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(knn_forest,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(knn_forest,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knn_forest' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [2, 5, 7, 10]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_sbert, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "knn_prediction = best_knn.predict(X_test_sbert)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, knn_prediction)\n",
    "precision_knn = precision_score(y_test, knn_prediction)\n",
    "recall_knn = recall_score(y_test, knn_prediction)\n",
    "f1_knn = f1_score(y_test, knn_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "18cfd29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 10}\n",
      "Accuracy: 0.831\n",
      "Precision: 0.863\n",
      "Recall: 0.786\n",
      "F1 Score: 0.823\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ac3f1943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 10}\n",
      "Accuracy: 0.835\n",
      "Precision: 0.862\n",
      "Recall: 0.799\n",
      "F1 Score: 0.829\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [2, 5, 7, 10]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_bert, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "knn_prediction = best_knn.predict(X_test_bert)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, knn_prediction)\n",
    "precision_knn = precision_score(y_test, knn_prediction)\n",
    "recall_knn = recall_score(y_test, knn_prediction)\n",
    "f1_knn = f1_score(y_test, knn_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5a9e22f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 10}\n",
      "Accuracy: 0.849\n",
      "Precision: 0.89\n",
      "Recall: 0.797\n",
      "F1 Score: 0.841\n",
      "F1 Score: 0.841\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [2, 5, 7, 10]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_roberta, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "knn_prediction = best_knn.predict(X_test_roberta)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, knn_prediction)\n",
    "precision_knn = precision_score(y_test, knn_prediction)\n",
    "recall_knn = recall_score(y_test, knn_prediction)\n",
    "f1_knn = f1_score(y_test, knn_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea75ee",
   "metadata": {},
   "source": [
    "## Neural Network - SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ca06a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:11<00:00, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:14 - loss: 0.2144 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2551 - accuracy: 0.8942\n",
      "Test loss: 0.25507253408432007\n",
      "Test accuracy: 0.8942196369171143\n",
      "2541/2541 [==============================] - 2s 840us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33f6ff5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:46<00:00, 22.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:03 - loss: 0.2739 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3042 - accuracy: 0.8926\n",
      "Test loss: 0.3042473793029785\n",
      "Test accuracy: 0.892583966255188\n",
      "2541/2541 [==============================] - 2s 916us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(256, activation='relu'), \n",
    "    keras.layers.Dense(128, activation='relu'), \n",
    "    keras.layers.Dense(64, activation='relu'), \n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87889d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:25<00:00, 20.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:06 - loss: 0.2456 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2613 - accuracy: 0.8922\n",
      "Test loss: 0.2613432705402374\n",
      "Test accuracy: 0.892227292060852\n",
      "2541/2541 [==============================] - 2s 861us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef07b267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:08<00:00, 18.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:03 - loss: 0.3022 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2564 - accuracy: 0.8947\n",
      "Test loss: 0.25637006759643555\n",
      "Test accuracy: 0.8947485089302063\n",
      "2541/2541 [==============================] - 2s 840us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9)\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "404ccb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895\n",
      "F1 Score: 0.894\n",
      "Precision: 0.897\n",
      "Recall: 0.891\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = [0 if num < 0.5 else 1 for num in predictions]\n",
    "\n",
    "accuracy_nn = accuracy_score(y_test, nn_predictions)\n",
    "precision_nn = precision_score(y_test, nn_predictions)\n",
    "recall_nn = recall_score(y_test, nn_predictions)\n",
    "f1_nn = f1_score(y_test, nn_predictions)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_nn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_nn, 3)}\")\n",
    "print(f\"Precision: {round(precision_nn, 3)}\")\n",
    "print(f\"Recall: {round(recall_nn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c705d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [04:24<00:00, 26.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:03 - loss: 0.2390 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2575 - accuracy: 0.8951\n",
      "Test loss: 0.2575363218784332\n",
      "Test accuracy: 0.8950928449630737\n",
      "2541/2541 [==============================] - 2s 888us/step\n"
     ]
    }
   ],
   "source": [
    "# Deep\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c1369b",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4492725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:19<00:00, 19.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2335 - accuracy: 0.9046\n",
      "Test loss: 0.23349975049495697\n",
      "Test accuracy: 0.9046489000320435\n",
      "2541/2541 [==============================] - 2s 882us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_bert[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_bert, y_train, batch_size=batch_size, validation_data=(X_test_bert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_bert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f028785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905\n",
      "F1 Score: 0.903\n",
      "Precision: 0.914\n",
      "Recall: 0.894\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = [0 if num < 0.5 else 1 for num in predictions]\n",
    "\n",
    "accuracy_nn = accuracy_score(y_test, nn_predictions)\n",
    "precision_nn = precision_score(y_test, nn_predictions)\n",
    "recall_nn = recall_score(y_test, nn_predictions)\n",
    "f1_nn = f1_score(y_test, nn_predictions)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_nn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_nn, 3)}\")\n",
    "print(f\"Precision: {round(precision_nn, 3)}\")\n",
    "print(f\"Recall: {round(recall_nn, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bead16",
   "metadata": {},
   "source": [
    "## RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e91fed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:20<00:00, 20.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.1980 - accuracy: 0.9223\n",
      "Test loss: 0.19799984991550446\n",
      "Test accuracy: 0.9222850799560547\n",
      "2541/2541 [==============================] - 2s 886us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_roberta[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_roberta, y_train, batch_size=batch_size, validation_data=(X_test_roberta, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_roberta, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5162a321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922\n",
      "F1 Score: 0.92\n",
      "Precision: 0.95\n",
      "Recall: 0.892\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = [0 if num < 0.5 else 1 for num in predictions]\n",
    "\n",
    "accuracy_nn = accuracy_score(y_test, nn_predictions)\n",
    "precision_nn = precision_score(y_test, nn_predictions)\n",
    "recall_nn = recall_score(y_test, nn_predictions)\n",
    "f1_nn = f1_score(y_test, nn_predictions)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_nn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_nn, 3)}\")\n",
    "print(f\"Precision: {round(precision_nn, 3)}\")\n",
    "print(f\"Recall: {round(recall_nn, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a885df7",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b5b10dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /cluster/home/olavanom/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3945caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f92002e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2293826/2463601894.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_compound'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
      "/tmp/ipykernel_2293826/2463601894.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_positive'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['pos'])\n",
      "/tmp/ipykernel_2293826/2463601894.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_negative'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['neg'])\n"
     ]
    }
   ],
   "source": [
    "df['sentiment_compound'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "df['sentiment_positive'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['pos'])\n",
    "df['sentiment_negative'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f291e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5933567500024597\n",
      "0.624083749028405\n",
      "0.6437394846365004\n",
      "0.6672840599388018\n",
      "0.6817571356887747\n",
      "\n",
      "0.654527878626878\n",
      "\n",
      "0.7304623316311973\n",
      "0.7385917530033353\n",
      "0.7394870962346389\n",
      "0.7429676200596239\n",
      "0.7185522988675384\n",
      "\n",
      "0.7433562580556293\n"
     ]
    }
   ],
   "source": [
    "def filter_df(n):\n",
    "    return df[((df['positive'] == 1) & (df['sentiment_compound'] > n)) | ((df['positive'] == 0) & (df['sentiment_compound'] < n))]\n",
    "\n",
    "print(len(filter_df(-0.5)) / len(df))\n",
    "print(len(filter_df(-0.4)) / len(df))\n",
    "print(len(filter_df(-0.3)) / len(df))\n",
    "print(len(filter_df(-0.2)) / len(df))\n",
    "print(len(filter_df(-0.1)) / len(df))\n",
    "print(\"\")\n",
    "print(len(filter_df(0)) / len(df))\n",
    "print(\"\")\n",
    "print(len(filter_df(0.1)) / len(df))\n",
    "print(len(filter_df(0.2)) / len(df))\n",
    "print(len(filter_df(0.3)) / len(df))\n",
    "print(len(filter_df(0.4)) / len(df))\n",
    "print(len(filter_df(0.5)) / len(df))\n",
    "print(\"\")\n",
    "print(len(filter_df(0.42)) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62195353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6539793579109969\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[((df['positive'] == 1) & (df['sentiment_positive'] > df['sentiment_negative'])) | ((df['positive'] == 0) & (df['sentiment_negative'] > df['sentiment_positive']))]\n",
    "\n",
    "print(len(filtered_df)/len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
