{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b1a3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import re\n",
    "import gzip\n",
    "import torch\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "\n",
    "from ast import literal_eval\n",
    "from itertools import zip_longest\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer, util, models\n",
    "from tensorflow import keras\n",
    "from torch.cuda import is_available\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error, mean_absolute_error, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309deec3",
   "metadata": {},
   "source": [
    "## Extract dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478995b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df_0 = getDF('Sports_and_Outdoors_5.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9b6d0",
   "metadata": {},
   "source": [
    "## Clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c21b05f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>What a spectacular tutu! Very slimming.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>What the heck? Is this a tutu for nuns? I know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Exactly what we were looking for!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I used this skirt for a Halloween costume and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>This is thick enough that you can't see throug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review\n",
       "0     5.0            What a spectacular tutu! Very slimming.\n",
       "1     1.0  What the heck? Is this a tutu for nuns? I know...\n",
       "2     5.0                  Exactly what we were looking for!\n",
       "3     5.0  I used this skirt for a Halloween costume and ...\n",
       "4     4.0  This is thick enough that you can't see throug..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_0[[\"overall\", \"reviewText\"]]\n",
    "df = df.rename(columns={\"overall\": \"rating\", \"reviewText\": \"review\"})\n",
    "df[\"review\"] = df[\"review\"].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f7a52",
   "metadata": {},
   "source": [
    "#### Observe that the majority of votes are 5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14bbd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5.0    1921398\n",
       "4.0     495533\n",
       "3.0     210215\n",
       "1.0     111157\n",
       "2.0     101637\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817140a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Rating')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cplot = sns.countplot(data=df_0[[\"overall\", \"reviewText\"]], x=\"overall\")\n",
    "cplot.set_xlabel(\"Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5596d",
   "metadata": {},
   "source": [
    "# SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3debcf4",
   "metadata": {},
   "source": [
    "#### Balance dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "888ef37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating_count = df['rating'].value_counts().min()\n",
    "\n",
    "balanced_dfs = []\n",
    "\n",
    "for rating in df['rating'].unique():\n",
    "    rating_df = df[df['rating'] == rating]\n",
    "    selected_rows = rating_df.sample(n=min_rating_count, random_state=1)\n",
    "    balanced_dfs.append(selected_rows)\n",
    "\n",
    "balanced_df = pd.concat(balanced_dfs)\n",
    "df = balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a12a4",
   "metadata": {},
   "source": [
    "#### Add SBERT encodings of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb043aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Model is running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508185/508185 [1:11:50<00:00, 117.89it/s]\n"
     ]
    }
   ],
   "source": [
    "sbert_model = SentenceTransformer(model_name_or_path='paraphrase-MiniLM-L12-v2')\n",
    "\n",
    "sbert_model.max_seq_length = 512\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    sbert_model.to('cuda')\n",
    "    print(\"Using GPU\")\n",
    "    print(f\"Model is running on device: {next(sbert_model.parameters()).device}\")\n",
    "\n",
    "encoded_reviews = []\n",
    "\n",
    "def encode_text_with_progress(text):\n",
    "    encoding = sbert_model.encode(text)\n",
    "    return encoding\n",
    "\n",
    "for text in tqdm(df['review']):\n",
    "    encoded_reviews.append(encode_text_with_progress(text).flatten())\n",
    "\n",
    "df['encoded_review'] = encoded_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9febcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Model is running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508185/508185 [1:06:27<00:00, 127.44it/s]\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    bert_model.to('cuda')\n",
    "    print(\"Using GPU\")\n",
    "    print(f\"Model is running on device: {next(bert_model.parameters()).device}\")\n",
    "\n",
    "encoded_reviews_bert = []\n",
    "\n",
    "def encode_text_with_progress_bert(text):\n",
    "    tokens = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**tokens)\n",
    "\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    pooled_embedding = torch.mean(embeddings, dim=1)\n",
    "\n",
    "    return pooled_embedding\n",
    "\n",
    "for text in tqdm(df['review']):\n",
    "    encoding = encode_text_with_progress_bert(text).flatten().cpu().numpy()\n",
    "    encoded_reviews_bert.append(encoding)\n",
    "\n",
    "max_len = max(len(enc) for enc in encoded_reviews_bert)\n",
    "padded_encodings = [np.pad(enc, (0, max_len - len(enc))) for enc in encoded_reviews_bert]\n",
    "\n",
    "df[\"encoded_review_bert\"] = padded_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3db5ae28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec10f79f7c68410aa6eab24c5c54497d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bb67d315aa45f7a82a10287f494e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77959071643425b95136cbb1438203f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be026546bf442918839a609e74024fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Model is running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508185/508185 [1:02:30<00:00, 135.51it/s]\n"
     ]
    }
   ],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    roberta_model.to('cuda')\n",
    "    print(\"Using GPU\")\n",
    "    print(f\"Model is running on device: {next(roberta_model.parameters()).device}\")\n",
    "\n",
    "encoded_reviews_roberta = []\n",
    "\n",
    "def encode_text_with_progress_roberta(text):\n",
    "    tokens = roberta_tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        tokens = {key: val.to('cuda') for key, val in tokens.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = roberta_model(**tokens)\n",
    "\n",
    "    encoding = output.last_hidden_state.mean(dim=1).flatten()\n",
    "    return encoding.cpu().numpy()\n",
    "\n",
    "for text in tqdm(df['review']):\n",
    "    encoded_reviews_roberta.append(encode_text_with_progress_roberta(text))\n",
    "\n",
    "df['encoded_review_roberta'] = encoded_reviews_roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee38b32",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d98d78",
   "metadata": {},
   "source": [
    "# 5-way classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37e1b8",
   "metadata": {},
   "source": [
    "## Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2522725f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5.]), array([81350, 81283, 81264, 81385, 81266]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sbert, X_test_sbert, y_train, y_test = train_test_split(np.array(df[\"encoded_review_sbert\"].values.tolist()), df[\"rating\"].values, test_size=0.2, random_state=SEED)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a94974bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5.]), array([81350, 81283, 81264, 81385, 81266]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(df[\"encoded_review_bert\"].values.tolist(), df[\"rating\"].values, test_size=0.2, random_state=SEED)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "50b31f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5.]), array([81350, 81283, 81264, 81385, 81266]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_roberta, X_test_roberta, y_train, y_test = train_test_split(df[\"encoded_review_roberta\"].values.tolist(), df[\"rating\"].values, test_size=0.2, random_state=SEED)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31fdd7",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "82045763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.381\n",
      "Average difference between predicted rating and ground truth: 1.009\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "decision_tree.fit(X_train_sbert, y_train)\n",
    "y_pred = decision_tree.predict(X_test_sbert)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1124e6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.386\n",
      "Average difference between predicted rating and ground truth: 1.016\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "decision_tree.fit(X_train_bert, y_train)\n",
    "y_pred = decision_tree.predict(X_test_bert)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "def84f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.395\n",
      "Average difference between predicted rating and ground truth: 0.982\n"
     ]
    }
   ],
   "source": [
    "# ROBERTA\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "decision_tree.fit(X_train_roberta, y_train)\n",
    "y_pred = decision_tree.predict(X_test_roberta)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b56387",
   "metadata": {},
   "source": [
    "#### Cross validate decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f1f2ac9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Test Accuracy with Best Model: 0.381\n",
      "Average difference between predicted rating and ground truth: 0.925\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_sbert, y_train)\n",
    "\n",
    "best_decision_tree = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_decision_tree.predict(X_test_sbert)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(f\"Test Accuracy with Best Model: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "46324d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Test Accuracy with Best Model: 0.385\n",
      "Average difference between predicted rating and ground truth: 0.962\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_bert, y_train)\n",
    "\n",
    "best_decision_tree = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_decision_tree.predict(X_test_bert)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(f\"Test Accuracy with Best Model: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9982d153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Test Accuracy with Best Model: 0.398\n",
      "Average difference between predicted rating and ground truth: 0.918\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_roberta, y_train)\n",
    "\n",
    "best_decision_tree = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_decision_tree.predict(X_test_roberta)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(f\"Test Accuracy with Best Model: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets)/len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47a756",
   "metadata": {},
   "source": [
    "## SVC (c for discrete classification, m for continous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d1651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.496\n",
      "Average difference between predicted rating and ground truth: 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "linear_svc_classifier = LinearSVC(random_state=SEED)\n",
    "linear_svc_classifier.fit(X_train_sbert, y_train)\n",
    "y_pred = linear_svc_classifier.predict(X_test_sbert)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c8c35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.516\n",
      "Average difference between predicted rating and ground truth: 0.655\n"
     ]
    }
   ],
   "source": [
    "#BERT\n",
    "\n",
    "linear_svc_classifier = LinearSVC(random_state=SEED)\n",
    "linear_svc_classifier.fit(X_train_bert, y_train)\n",
    "y_pred = linear_svc_classifier.predict(X_test_bert)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6b75cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.541\n",
      "Average difference between predicted rating and ground truth: 0.595\n"
     ]
    }
   ],
   "source": [
    "#ROBERTA\n",
    "\n",
    "linear_svc_classifier = LinearSVC(random_state=SEED)\n",
    "linear_svc_classifier.fit(X_train_roberta, y_train)\n",
    "y_pred = linear_svc_classifier.predict(X_test_roberta)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)}\")\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, y_pred)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33abf23",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e15bb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 11:28:03.940266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 77855 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:48:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 11:28:03.987034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78407 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:8a:00.0, compute capability: 8.0\n",
      "2023-11-13 11:28:03.988129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 78407 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c0:00.0, compute capability: 8.0\n",
      "2023-11-13 11:28:03.989111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 78407 MB memory:  -> device: 3, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c1:00.0, compute capability: 8.0\n",
      "2023-11-13 11:28:11.722179: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-13 11:28:12.484572: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558dd2648f10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-13 11:28:12.484606: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-13 11:28:12.484612: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-13 11:28:12.484616: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-13 11:28:12.484620: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-13 11:28:12.794165: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-13 11:28:13.373971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-13 11:28:14.018950: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12705/12705 [==============================] - 31s 2ms/step - loss: 1.1341 - accuracy: 0.4985 - val_loss: 1.1105 - val_accuracy: 0.5096\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0979 - accuracy: 0.5158 - val_loss: 1.1013 - val_accuracy: 0.5127\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0827 - accuracy: 0.5224 - val_loss: 1.0962 - val_accuracy: 0.5164\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0722 - accuracy: 0.5280 - val_loss: 1.0994 - val_accuracy: 0.5153\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0636 - accuracy: 0.5320 - val_loss: 1.0981 - val_accuracy: 0.5170\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0569 - accuracy: 0.5360 - val_loss: 1.0972 - val_accuracy: 0.5151\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0518 - accuracy: 0.5383 - val_loss: 1.0991 - val_accuracy: 0.5174\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0466 - accuracy: 0.5412 - val_loss: 1.1014 - val_accuracy: 0.5167\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0425 - accuracy: 0.5429 - val_loss: 1.0973 - val_accuracy: 0.5168\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0389 - accuracy: 0.5447 - val_loss: 1.0988 - val_accuracy: 0.5174\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.0988 - accuracy: 0.5174\n",
      "Test loss: 1.0988471508026123, Test accuracy: 0.5174099802970886\n",
      "3177/3177 [==============================] - 3s 824us/step\n",
      "Average difference between predicted rating and ground truth: 0.624\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train_sbert)\n",
    "X_test = np.array(X_test_sbert)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train - 1, num_classes=5)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test - 1, num_classes=5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e32f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1328 - accuracy: 0.4969 - val_loss: 1.1068 - val_accuracy: 0.5102\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0920 - accuracy: 0.5168 - val_loss: 1.0961 - val_accuracy: 0.5160\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0719 - accuracy: 0.5261 - val_loss: 1.0890 - val_accuracy: 0.5186\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0547 - accuracy: 0.5341 - val_loss: 1.0915 - val_accuracy: 0.5194\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0410 - accuracy: 0.5400 - val_loss: 1.0939 - val_accuracy: 0.5190\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0281 - accuracy: 0.5464 - val_loss: 1.0978 - val_accuracy: 0.5204\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0159 - accuracy: 0.5517 - val_loss: 1.0958 - val_accuracy: 0.5220\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 1.0049 - accuracy: 0.5564 - val_loss: 1.1014 - val_accuracy: 0.5203\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 0.9943 - accuracy: 0.5618 - val_loss: 1.1072 - val_accuracy: 0.5184\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 28s 2ms/step - loss: 0.9847 - accuracy: 0.5657 - val_loss: 1.1119 - val_accuracy: 0.5202\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.1119 - accuracy: 0.5202\n",
      "Test loss: 1.1119333505630493, Test accuracy: 0.5202435851097107\n",
      "3177/3177 [==============================] - 3s 881us/step\n",
      "Average difference between predicted rating and ground truth: 0.617\n"
     ]
    }
   ],
   "source": [
    "# Deep NN\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e02c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 33s 2ms/step - loss: 1.2180 - accuracy: 0.4621 - val_loss: 1.1392 - val_accuracy: 0.4976\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1806 - accuracy: 0.4791 - val_loss: 1.1357 - val_accuracy: 0.4970\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1737 - accuracy: 0.4824 - val_loss: 1.1317 - val_accuracy: 0.5013\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1669 - accuracy: 0.4855 - val_loss: 1.1271 - val_accuracy: 0.4991\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1629 - accuracy: 0.4883 - val_loss: 1.1210 - val_accuracy: 0.5027\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1611 - accuracy: 0.4882 - val_loss: 1.1241 - val_accuracy: 0.5072\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1570 - accuracy: 0.4902 - val_loss: 1.1173 - val_accuracy: 0.5045\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1565 - accuracy: 0.4910 - val_loss: 1.1169 - val_accuracy: 0.5043\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1548 - accuracy: 0.4909 - val_loss: 1.1183 - val_accuracy: 0.5097\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.1522 - accuracy: 0.4929 - val_loss: 1.1128 - val_accuracy: 0.5098\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.1128 - accuracy: 0.5098\n",
      "Test loss: 1.1127856969833374, Test accuracy: 0.5097553133964539\n",
      "3177/3177 [==============================] - 3s 896us/step\n",
      "Average difference between predicted rating and ground truth: 0.624\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c34931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 180s 14ms/step - loss: 1.6097 - accuracy: 0.1992 - val_loss: 1.6095 - val_accuracy: 0.1993\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 175s 14ms/step - loss: 1.6096 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.1996\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 173s 14ms/step - loss: 1.6095 - accuracy: 0.2003 - val_loss: 1.6096 - val_accuracy: 0.2004\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 175s 14ms/step - loss: 1.6095 - accuracy: 0.2008 - val_loss: 1.6096 - val_accuracy: 0.2004\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 175s 14ms/step - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6094 - val_accuracy: 0.1996\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 175s 14ms/step - loss: 1.6095 - accuracy: 0.2000 - val_loss: 1.6097 - val_accuracy: 0.1996\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 176s 14ms/step - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6096 - val_accuracy: 0.1992\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 176s 14ms/step - loss: 1.6095 - accuracy: 0.2009 - val_loss: 1.6095 - val_accuracy: 0.2004\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 176s 14ms/step - loss: 1.6095 - accuracy: 0.1998 - val_loss: 1.6096 - val_accuracy: 0.1996\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 173s 14ms/step - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6095 - val_accuracy: 0.2004\n",
      "3177/3177 [==============================] - 19s 6ms/step - loss: 1.6095 - accuracy: 0.2004\n",
      "Test loss: 1.6094820499420166, Test accuracy: 0.20042897760868073\n",
      "3177/3177 [==============================] - 16s 5ms/step\n",
      "Average difference between predicted rating and ground truth: 1.999\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(input_dim=1000, output_dim=64))\n",
    "rnn_model.add(LSTM(128))\n",
    "rnn_model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "rnn_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "rnn_model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = rnn_model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = rnn_model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfbcdf7",
   "metadata": {},
   "source": [
    "## BERT NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b956a1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:55:01.560496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 77543 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:48:00.0, compute capability: 8.0\n",
      "2023-11-10 12:55:01.606642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78407 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:8a:00.0, compute capability: 8.0\n",
      "2023-11-10 12:55:01.607849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 78407 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c0:00.0, compute capability: 8.0\n",
      "2023-11-10 12:55:01.608891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 78407 MB memory:  -> device: 3, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:55:11.279643: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-10 12:55:12.089136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bbdd388e50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-10 12:55:12.089209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-10 12:55:12.089215: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-10 12:55:12.089218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-10 12:55:12.089222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-10 12:55:12.415133: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-10 12:55:12.943346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-10 12:55:13.444512: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12705/12705 [==============================] - 32s 2ms/step - loss: 1.1202 - accuracy: 0.5047 - val_loss: 1.0989 - val_accuracy: 0.5135\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0851 - accuracy: 0.5195 - val_loss: 1.0813 - val_accuracy: 0.5220\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0727 - accuracy: 0.5258 - val_loss: 1.0822 - val_accuracy: 0.5206\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0643 - accuracy: 0.5305 - val_loss: 1.0676 - val_accuracy: 0.5291\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0579 - accuracy: 0.5329 - val_loss: 1.0682 - val_accuracy: 0.5277\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0529 - accuracy: 0.5352 - val_loss: 1.0648 - val_accuracy: 0.5283\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0485 - accuracy: 0.5366 - val_loss: 1.0765 - val_accuracy: 0.5243\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0450 - accuracy: 0.5381 - val_loss: 1.0757 - val_accuracy: 0.5254\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0413 - accuracy: 0.5406 - val_loss: 1.0646 - val_accuracy: 0.5315\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 25s 2ms/step - loss: 1.0389 - accuracy: 0.5409 - val_loss: 1.0600 - val_accuracy: 0.5320\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.0600 - accuracy: 0.5320\n",
      "Test loss: 1.0599929094314575, Test accuracy: 0.5320109724998474\n",
      "3177/3177 [==============================] - 3s 878us/step\n",
      "Average difference between predicted rating and ground truth: 0.586\n"
     ]
    }
   ],
   "source": [
    "X_train_bert = np.array(X_train_bert)\n",
    "X_test_bert = np.array(X_test_bert)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train - 1, num_classes=5)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test - 1, num_classes=5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train_bert.shape[1],)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_bert, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test_bert, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_bert, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test_bert)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0344c998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 31s 2ms/step - loss: 1.1223 - accuracy: 0.5028 - val_loss: 1.1004 - val_accuracy: 0.5155\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0844 - accuracy: 0.5201 - val_loss: 1.0914 - val_accuracy: 0.5163\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0704 - accuracy: 0.5271 - val_loss: 1.0681 - val_accuracy: 0.5304\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0595 - accuracy: 0.5321 - val_loss: 1.0724 - val_accuracy: 0.5274\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0514 - accuracy: 0.5355 - val_loss: 1.0640 - val_accuracy: 0.5316\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0442 - accuracy: 0.5379 - val_loss: 1.0653 - val_accuracy: 0.5302\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0381 - accuracy: 0.5407 - val_loss: 1.0586 - val_accuracy: 0.5340\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0331 - accuracy: 0.5429 - val_loss: 1.0593 - val_accuracy: 0.5342\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0273 - accuracy: 0.5458 - val_loss: 1.0707 - val_accuracy: 0.5281\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0226 - accuracy: 0.5478 - val_loss: 1.0693 - val_accuracy: 0.5304\n",
      "3177/3177 [==============================] - 5s 1ms/step - loss: 1.0693 - accuracy: 0.5304\n",
      "Test loss: 1.0693244934082031, Test accuracy: 0.5303974151611328\n",
      "3177/3177 [==============================] - 3s 959us/step\n",
      "Average difference between predicted rating and ground truth: 0.59\n"
     ]
    }
   ],
   "source": [
    "X_train_bert = np.array(X_train_bert)\n",
    "X_test_bert = np.array(X_test_bert)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train - 1, num_classes=5)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test - 1, num_classes=5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train_bert.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_bert, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test_bert, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_bert, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test_bert)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298144d2",
   "metadata": {},
   "source": [
    "## ROBERTA NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5414266d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 33s 2ms/step - loss: 1.0558 - accuracy: 0.5328 - val_loss: 1.0302 - val_accuracy: 0.5438\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0171 - accuracy: 0.5506 - val_loss: 1.0416 - val_accuracy: 0.5405\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 1.0039 - accuracy: 0.5560 - val_loss: 1.0085 - val_accuracy: 0.5549\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9953 - accuracy: 0.5600 - val_loss: 1.0068 - val_accuracy: 0.5555\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9878 - accuracy: 0.5633 - val_loss: 1.0062 - val_accuracy: 0.5553\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9818 - accuracy: 0.5665 - val_loss: 1.0014 - val_accuracy: 0.5574\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9769 - accuracy: 0.5681 - val_loss: 1.0029 - val_accuracy: 0.5572\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9726 - accuracy: 0.5708 - val_loss: 1.0006 - val_accuracy: 0.5542\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9683 - accuracy: 0.5722 - val_loss: 1.0010 - val_accuracy: 0.5570\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 24s 2ms/step - loss: 0.9644 - accuracy: 0.5744 - val_loss: 1.0031 - val_accuracy: 0.5567\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.0031 - accuracy: 0.5567\n",
      "Test loss: 1.0031391382217407, Test accuracy: 0.5567460656166077\n",
      "3177/3177 [==============================] - 3s 853us/step\n",
      "Average difference between predicted rating and ground truth: 0.541\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train_roberta)\n",
    "X_test = np.array(X_test_roberta)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train - 1, num_classes=5)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test - 1, num_classes=5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdf5c257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12705/12705 [==============================] - 30s 2ms/step - loss: 1.0542 - accuracy: 0.5327 - val_loss: 1.0243 - val_accuracy: 0.5470\n",
      "Epoch 2/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0169 - accuracy: 0.5507 - val_loss: 1.0134 - val_accuracy: 0.5522\n",
      "Epoch 3/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 1.0018 - accuracy: 0.5572 - val_loss: 1.0115 - val_accuracy: 0.5526\n",
      "Epoch 4/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9909 - accuracy: 0.5618 - val_loss: 1.0023 - val_accuracy: 0.5552\n",
      "Epoch 5/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9822 - accuracy: 0.5646 - val_loss: 1.0049 - val_accuracy: 0.5568\n",
      "Epoch 6/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9747 - accuracy: 0.5695 - val_loss: 0.9972 - val_accuracy: 0.5581\n",
      "Epoch 7/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9678 - accuracy: 0.5715 - val_loss: 1.0078 - val_accuracy: 0.5550\n",
      "Epoch 8/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9610 - accuracy: 0.5747 - val_loss: 0.9949 - val_accuracy: 0.5613\n",
      "Epoch 9/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9548 - accuracy: 0.5772 - val_loss: 1.0280 - val_accuracy: 0.5508\n",
      "Epoch 10/10\n",
      "12705/12705 [==============================] - 29s 2ms/step - loss: 0.9486 - accuracy: 0.5805 - val_loss: 1.0001 - val_accuracy: 0.5596\n",
      "3177/3177 [==============================] - 4s 1ms/step - loss: 1.0001 - accuracy: 0.5596\n",
      "Test loss: 1.0000765323638916, Test accuracy: 0.5595796704292297\n",
      "3177/3177 [==============================] - 3s 925us/step\n",
      "Average difference between predicted rating and ground truth: 0.537\n"
     ]
    }
   ],
   "source": [
    "# Deep NN\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test, y_test_ohe))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_ohe)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "offsets = [abs(t - p) for t, p in zip(y_test, np.argmax(predictions, axis=1) + 1)]\n",
    "\n",
    "print(f\"Average difference between predicted rating and ground truth: {round(sum(offsets) / len(offsets), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a4ed1",
   "metadata": {},
   "source": [
    "# Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373e01d",
   "metadata": {},
   "source": [
    "#### Make 1&2 star ratings negative and 4&5 star ratings positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d85f06d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2410528/1005697633.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[\"positive\"] = (df2[\"rating\"] > 3).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>encoded_review_sbert</th>\n",
       "      <th>encoded_review_roberta</th>\n",
       "      <th>encoded_review_bert</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>830792</th>\n",
       "      <td>5.0</td>\n",
       "      <td>lazer nice but worth having the grip perfect</td>\n",
       "      <td>[-0.1466909, -0.12516333, -0.5601697, -0.04356...</td>\n",
       "      <td>[-0.062008798, 0.18042147, -0.06070903, -0.032...</td>\n",
       "      <td>[-0.123875156, -0.24859346, 0.24571559, 0.2377...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850653</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I just received my UTG pack yesterday, and aft...</td>\n",
       "      <td>[-0.2469892, 0.42250115, -0.17435247, -0.09039...</td>\n",
       "      <td>[-0.026691116, 0.20569725, 0.0012298374, -0.05...</td>\n",
       "      <td>[-0.1667779, -0.033920705, 0.22260371, 0.09758...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626724</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Does not leak (as long as you put the cap on r...</td>\n",
       "      <td>[-0.24478982, 0.17316727, -0.12371678, -0.4412...</td>\n",
       "      <td>[0.001923264, 0.039070137, 0.00090832263, -0.0...</td>\n",
       "      <td>[0.14108594, -0.23224497, 0.39572367, -0.20799...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367874</th>\n",
       "      <td>5.0</td>\n",
       "      <td>bright light works great for my college son. J...</td>\n",
       "      <td>[0.020240288, -0.10725535, 0.2922491, 0.305173...</td>\n",
       "      <td>[-0.002267656, 0.13629214, 0.008082978, -0.117...</td>\n",
       "      <td>[0.3685369, 0.085767716, 0.44435415, -0.103456...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769707</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This is my 4th top for my 40oz fifty-fifty bot...</td>\n",
       "      <td>[-0.07240746, -0.0045981924, 0.05199444, -0.02...</td>\n",
       "      <td>[-0.038737267, 0.11030901, -0.031557377, -0.13...</td>\n",
       "      <td>[-0.17748058, 0.009539982, 0.44630298, 0.00836...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446259</th>\n",
       "      <td>2.0</td>\n",
       "      <td>These are pretty cheap.  The big ones are okay...</td>\n",
       "      <td>[-0.048299145, 0.12944467, 0.31336844, -0.0091...</td>\n",
       "      <td>[0.01072515, 0.1995503, 0.031587593, -0.195092...</td>\n",
       "      <td>[0.10510927, 0.042450733, 0.13578537, 0.196205...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759763</th>\n",
       "      <td>2.0</td>\n",
       "      <td>to hard to use. not worth the money</td>\n",
       "      <td>[-0.37008867, -0.29714772, -0.24915065, 0.1546...</td>\n",
       "      <td>[-0.08465307, 0.04587426, -0.008179868, -0.035...</td>\n",
       "      <td>[-0.04212603, -0.25559938, 0.069136925, 0.2609...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157566</th>\n",
       "      <td>2.0</td>\n",
       "      <td>This sword display would be ok for the price, ...</td>\n",
       "      <td>[-0.118137226, 0.19106281, 0.012811152, -0.007...</td>\n",
       "      <td>[-0.036841143, 0.123045094, 0.056401867, -0.00...</td>\n",
       "      <td>[-0.22836113, -0.08283205, 0.21313386, 0.09037...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211288</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Too wide in all directions.</td>\n",
       "      <td>[0.6949, -0.16437449, 0.18026513, 0.17394236, ...</td>\n",
       "      <td>[-0.0057778587, 0.029149929, 0.06683141, -0.07...</td>\n",
       "      <td>[-0.38585982, -0.19612728, 0.28427878, -0.1135...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771815</th>\n",
       "      <td>2.0</td>\n",
       "      <td>They aren't consistent sizes or weights at all.</td>\n",
       "      <td>[-0.2646532, -0.053607605, 0.3164193, 0.044488...</td>\n",
       "      <td>[0.019586608, 0.10958537, -0.050748657, -0.061...</td>\n",
       "      <td>[0.3365965, 0.20294352, 0.15622438, 0.30686295...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406548 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  \\\n",
       "830792      5.0       lazer nice but worth having the grip perfect   \n",
       "850653      5.0  I just received my UTG pack yesterday, and aft...   \n",
       "1626724     5.0  Does not leak (as long as you put the cap on r...   \n",
       "1367874     5.0  bright light works great for my college son. J...   \n",
       "1769707     5.0  This is my 4th top for my 40oz fifty-fifty bot...   \n",
       "...         ...                                                ...   \n",
       "1446259     2.0  These are pretty cheap.  The big ones are okay...   \n",
       "2759763     2.0                to hard to use. not worth the money   \n",
       "157566      2.0  This sword display would be ok for the price, ...   \n",
       "2211288     2.0                        Too wide in all directions.   \n",
       "2771815     2.0    They aren't consistent sizes or weights at all.   \n",
       "\n",
       "                                      encoded_review_sbert  \\\n",
       "830792   [-0.1466909, -0.12516333, -0.5601697, -0.04356...   \n",
       "850653   [-0.2469892, 0.42250115, -0.17435247, -0.09039...   \n",
       "1626724  [-0.24478982, 0.17316727, -0.12371678, -0.4412...   \n",
       "1367874  [0.020240288, -0.10725535, 0.2922491, 0.305173...   \n",
       "1769707  [-0.07240746, -0.0045981924, 0.05199444, -0.02...   \n",
       "...                                                    ...   \n",
       "1446259  [-0.048299145, 0.12944467, 0.31336844, -0.0091...   \n",
       "2759763  [-0.37008867, -0.29714772, -0.24915065, 0.1546...   \n",
       "157566   [-0.118137226, 0.19106281, 0.012811152, -0.007...   \n",
       "2211288  [0.6949, -0.16437449, 0.18026513, 0.17394236, ...   \n",
       "2771815  [-0.2646532, -0.053607605, 0.3164193, 0.044488...   \n",
       "\n",
       "                                    encoded_review_roberta  \\\n",
       "830792   [-0.062008798, 0.18042147, -0.06070903, -0.032...   \n",
       "850653   [-0.026691116, 0.20569725, 0.0012298374, -0.05...   \n",
       "1626724  [0.001923264, 0.039070137, 0.00090832263, -0.0...   \n",
       "1367874  [-0.002267656, 0.13629214, 0.008082978, -0.117...   \n",
       "1769707  [-0.038737267, 0.11030901, -0.031557377, -0.13...   \n",
       "...                                                    ...   \n",
       "1446259  [0.01072515, 0.1995503, 0.031587593, -0.195092...   \n",
       "2759763  [-0.08465307, 0.04587426, -0.008179868, -0.035...   \n",
       "157566   [-0.036841143, 0.123045094, 0.056401867, -0.00...   \n",
       "2211288  [-0.0057778587, 0.029149929, 0.06683141, -0.07...   \n",
       "2771815  [0.019586608, 0.10958537, -0.050748657, -0.061...   \n",
       "\n",
       "                                       encoded_review_bert  positive  \n",
       "830792   [-0.123875156, -0.24859346, 0.24571559, 0.2377...         1  \n",
       "850653   [-0.1667779, -0.033920705, 0.22260371, 0.09758...         1  \n",
       "1626724  [0.14108594, -0.23224497, 0.39572367, -0.20799...         1  \n",
       "1367874  [0.3685369, 0.085767716, 0.44435415, -0.103456...         1  \n",
       "1769707  [-0.17748058, 0.009539982, 0.44630298, 0.00836...         1  \n",
       "...                                                    ...       ...  \n",
       "1446259  [0.10510927, 0.042450733, 0.13578537, 0.196205...         0  \n",
       "2759763  [-0.04212603, -0.25559938, 0.069136925, 0.2609...         0  \n",
       "157566   [-0.22836113, -0.08283205, 0.21313386, 0.09037...         0  \n",
       "2211288  [-0.38585982, -0.19612728, 0.28427878, -0.1135...         0  \n",
       "2771815  [0.3365965, 0.20294352, 0.15622438, 0.30686295...         0  \n",
       "\n",
       "[406548 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df[\"rating\"] != 3]\n",
    "df2[\"positive\"] = (df2[\"rating\"] > 3).astype(int)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bfecf3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sbert, X_test_sbert, y_train, y_test = train_test_split(np.array(df2[\"encoded_review_sbert\"].values.tolist()), df2[\"positive\"].values, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "842641bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(np.array(df2[\"encoded_review_bert\"].values.tolist()), df2[\"positive\"].values, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9b1719a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_roberta, X_test_roberta, y_train, y_test = train_test_split(np.array(df2[\"encoded_review_roberta\"].values.tolist()), df2[\"positive\"].values, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b55fc24",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d704e08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 20}\n",
      "Accuracy: 0.88\n",
      "Precision: 0.885\n",
      "Recall: 0.873\n",
      "F1 Score: 0.879\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "param_grid = {\n",
    "    'C': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "logistic = LogisticRegression(random_state=SEED, max_iter=1000000)\n",
    "\n",
    "grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_sbert, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_logistic = grid_search.best_estimator_\n",
    "\n",
    "logistic_prediction = best_logistic.predict(X_test_sbert)\n",
    "\n",
    "accuracy_logistic = accuracy_score(y_test, logistic_prediction)\n",
    "precision_logistic = precision_score(y_test, logistic_prediction)\n",
    "recall_logistic = recall_score(y_test, logistic_prediction)\n",
    "f1_logistic = f1_score(y_test, logistic_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_logistic, 3)}\")\n",
    "print(f\"Precision: {round(precision_logistic, 3)}\")\n",
    "print(f\"Recall: {round(recall_logistic, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_logistic, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e4e2bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 15}\n",
      "Accuracy: 0.891\n",
      "Precision: 0.895\n",
      "Recall: 0.886\n",
      "F1 Score: 0.891\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "\n",
    "param_grid = {\n",
    "    'C': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "logistic = LogisticRegression(random_state=SEED, max_iter=1000000)\n",
    "\n",
    "grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_bert, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_logistic = grid_search.best_estimator_\n",
    "\n",
    "logistic_prediction = best_logistic.predict(X_test_bert)\n",
    "\n",
    "accuracy_logistic = accuracy_score(y_test, logistic_prediction)\n",
    "precision_logistic = precision_score(y_test, logistic_prediction)\n",
    "recall_logistic = recall_score(y_test, logistic_prediction)\n",
    "f1_logistic = f1_score(y_test, logistic_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_logistic, 3)}\")\n",
    "print(f\"Precision: {round(precision_logistic, 3)}\")\n",
    "print(f\"Recall: {round(recall_logistic, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_logistic, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "045317bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 25}\n",
      "Accuracy: 0.914\n",
      "Precision: 0.918\n",
      "Recall: 0.908\n",
      "F1 Score: 0.913\n"
     ]
    }
   ],
   "source": [
    "# ROBERTA\n",
    "\n",
    "param_grid = {\n",
    "    'C': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "logistic = LogisticRegression(random_state=SEED, max_iter=1000000)\n",
    "\n",
    "grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_roberta, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_logistic = grid_search.best_estimator_\n",
    "\n",
    "logistic_prediction = best_logistic.predict(X_test_roberta)\n",
    "\n",
    "accuracy_logistic = accuracy_score(y_test, logistic_prediction)\n",
    "precision_logistic = precision_score(y_test, logistic_prediction)\n",
    "recall_logistic = recall_score(y_test, logistic_prediction)\n",
    "f1_logistic = f1_score(y_test, logistic_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_logistic, 3)}\")\n",
    "print(f\"Precision: {round(precision_logistic, 3)}\")\n",
    "print(f\"Recall: {round(recall_logistic, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_logistic, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18412dbb",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722d6c18",
   "metadata": {},
   "source": [
    "#### Prepare random samples for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "820aef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "X_train_sbert_val = random.sample(X_train_sbert.tolist(), int(len(X_train_sbert.tolist()) * 0.05))\n",
    "X_test_sbert_val = random.sample(X_test_sbert.tolist(), int(len(X_test_sbert.tolist()) * 0.05))\n",
    "\n",
    "X_train_bert_val = random.sample(X_train_bert.tolist(), int(len(X_train_bert.tolist()) * 0.05))\n",
    "X_test_bert_val = random.sample(X_test_bert.tolist(), int(len(X_test_bert.tolist()) * 0.05))\n",
    "\n",
    "X_train_roberta_val = random.sample(X_train_roberta.tolist(), int(len(X_train_roberta.tolist()) * 0.05))\n",
    "X_test_roberta_val = random.sample(X_test_roberta.tolist(), int(len(X_test_roberta.tolist()) * 0.05))\n",
    "\n",
    "y_train_val = random.sample(y_train.tolist(), int(len(y_train.tolist()) * 0.05))\n",
    "y_test_val = random.sample(y_test.tolist(), int(len(y_test.tolist()) * 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "grid_search = GridSearchCV(random_forest, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfccd433",
   "metadata": {},
   "source": [
    "#### Cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "542854cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [20:07<5:01:58, 1207.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.502\n",
      "Precision: 0.498\n",
      "Recall: 0.627\n",
      "F1 Score: 0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_sbert_val, y_train_val)\n",
    "\n",
    "print(\"Best hyperparameters\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce43978a",
   "metadata": {},
   "source": [
    "#### Apply hyperparameters to the random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f29888fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.842\n",
      "Precision: 0.861\n",
      "Recall: 0.816\n",
      "F1 Score: 0.838\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=2, min_samples_split=2, random_state=SEED)\n",
    "random_forest.fit(X_train_sbert, y_train)\n",
    "\n",
    "random_forest_prediction = random_forest.predict(X_test_sbert)\n",
    "\n",
    "accuracy_random_forest = accuracy_score(y_test, random_forest_prediction)\n",
    "precision_random_forest = precision_score(y_test, random_forest_prediction)\n",
    "recall_random_forest = recall_score(y_test, random_forest_prediction)\n",
    "f1_random_forest = f1_score(y_test, random_forest_prediction)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_random_forest, 3)}\")\n",
    "print(f\"Precision: {round(precision_random_forest, 3)}\")\n",
    "print(f\"Recall: {round(recall_random_forest, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_random_forest, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bff866a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.851\n",
      "Precision: 0.88\n",
      "Recall: 0.812\n",
      "F1 Score: 0.845\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=2, min_samples_split=2, random_state=SEED)\n",
    "random_forest.fit(X_train_bert, y_train)\n",
    "\n",
    "random_forest_prediction = random_forest.predict(X_test_bert)\n",
    "\n",
    "accuracy_random_forest = accuracy_score(y_test, random_forest_prediction)\n",
    "precision_random_forest = precision_score(y_test, random_forest_prediction)\n",
    "recall_random_forest = recall_score(y_test, random_forest_prediction)\n",
    "f1_random_forest = f1_score(y_test, random_forest_prediction)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_random_forest, 3)}\")\n",
    "print(f\"Precision: {round(precision_random_forest, 3)}\")\n",
    "print(f\"Recall: {round(recall_random_forest, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_random_forest, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6246efdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.869\n",
      "Precision: 0.887\n",
      "Recall: 0.845\n",
      "F1 Score: 0.865\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa (with SBERT hyperparameters)\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=2, min_samples_split=2, random_state=SEED)\n",
    "random_forest.fit(X_train_roberta, y_train)\n",
    "\n",
    "random_forest_prediction = random_forest.predict(X_test_roberta)\n",
    "\n",
    "accuracy_random_forest = accuracy_score(y_test, random_forest_prediction)\n",
    "precision_random_forest = precision_score(y_test, random_forest_prediction)\n",
    "recall_random_forest = recall_score(y_test, random_forest_prediction)\n",
    "f1_random_forest = f1_score(y_test, random_forest_prediction)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_random_forest, 3)}\")\n",
    "print(f\"Precision: {round(precision_random_forest, 3)}\")\n",
    "print(f\"Recall: {round(recall_random_forest, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_random_forest, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1685e3",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c44041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819\n",
      "Precision: 0.821\n",
      "Recall: 0.816\n",
      "F1 Score: 0.818\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train_sbert, y_train)\n",
    "\n",
    "knn_predictions = knn.predict(X_test_sbert)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, knn_predictions)\n",
    "precision_knn = precision_score(y_test, knn_predictions)\n",
    "recall_knn = recall_score(y_test, knn_predictions)\n",
    "f1_knn = f1_score(y_test, knn_predictions)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40f2f0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 10}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'knn_forest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [127]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(knn_forest,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(knn_forest,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(knn_forest,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knn_forest' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [2, 5, 7, 10]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_sbert, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "knn_prediction = best_knn.predict(X_test_sbert)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, knn_prediction)\n",
    "precision_knn = precision_score(y_test, knn_prediction)\n",
    "recall_knn = recall_score(y_test, knn_prediction)\n",
    "f1_knn = f1_score(y_test, knn_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "18cfd29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 10}\n",
      "Accuracy: 0.831\n",
      "Precision: 0.863\n",
      "Recall: 0.786\n",
      "F1 Score: 0.823\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ac3f1943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 10}\n",
      "Accuracy: 0.835\n",
      "Precision: 0.862\n",
      "Recall: 0.799\n",
      "F1 Score: 0.829\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [2, 5, 7, 10]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_bert, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "knn_prediction = best_knn.predict(X_test_bert)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, knn_prediction)\n",
    "precision_knn = precision_score(y_test, knn_prediction)\n",
    "recall_knn = recall_score(y_test, knn_prediction)\n",
    "f1_knn = f1_score(y_test, knn_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5a9e22f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/cluster/apps/eb/software/Anaconda3/2022.05/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 10}\n",
      "Accuracy: 0.849\n",
      "Precision: 0.89\n",
      "Recall: 0.797\n",
      "F1 Score: 0.841\n",
      "F1 Score: 0.841\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [2, 5, 7, 10]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_roberta, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "knn_prediction = best_knn.predict(X_test_roberta)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, knn_prediction)\n",
    "precision_knn = precision_score(y_test, knn_prediction)\n",
    "recall_knn = recall_score(y_test, knn_prediction)\n",
    "f1_knn = f1_score(y_test, knn_prediction)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {round(accuracy_knn, 3)}\")\n",
    "print(f\"Precision: {round(precision_knn, 3)}\")\n",
    "print(f\"Recall: {round(recall_knn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_knn, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea75ee",
   "metadata": {},
   "source": [
    "## Neural Network - SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ca06a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:11<00:00, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:14 - loss: 0.2144 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2551 - accuracy: 0.8942\n",
      "Test loss: 0.25507253408432007\n",
      "Test accuracy: 0.8942196369171143\n",
      "2541/2541 [==============================] - 2s 840us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33f6ff5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:46<00:00, 22.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:03 - loss: 0.2739 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.3042 - accuracy: 0.8926\n",
      "Test loss: 0.3042473793029785\n",
      "Test accuracy: 0.892583966255188\n",
      "2541/2541 [==============================] - 2s 916us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(256, activation='relu'), \n",
    "    keras.layers.Dense(128, activation='relu'), \n",
    "    keras.layers.Dense(64, activation='relu'), \n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87889d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:25<00:00, 20.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:06 - loss: 0.2456 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2613 - accuracy: 0.8922\n",
      "Test loss: 0.2613432705402374\n",
      "Test accuracy: 0.892227292060852\n",
      "2541/2541 [==============================] - 2s 861us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef07b267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:08<00:00, 18.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:03 - loss: 0.3022 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2564 - accuracy: 0.8947\n",
      "Test loss: 0.25637006759643555\n",
      "Test accuracy: 0.8947485089302063\n",
      "2541/2541 [==============================] - 2s 840us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9)\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "404ccb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895\n",
      "F1 Score: 0.894\n",
      "Precision: 0.897\n",
      "Recall: 0.891\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = [0 if num < 0.5 else 1 for num in predictions]\n",
    "\n",
    "accuracy_nn = accuracy_score(y_test, nn_predictions)\n",
    "precision_nn = precision_score(y_test, nn_predictions)\n",
    "recall_nn = recall_score(y_test, nn_predictions)\n",
    "f1_nn = f1_score(y_test, nn_predictions)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_nn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_nn, 3)}\")\n",
    "print(f\"Precision: {round(precision_nn, 3)}\")\n",
    "print(f\"Recall: {round(recall_nn, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c705d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [04:24<00:00, 26.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2541 [..............................] - ETA: 1:03 - loss: 0.2390 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2575 - accuracy: 0.8951\n",
      "Test loss: 0.2575363218784332\n",
      "Test accuracy: 0.8950928449630737\n",
      "2541/2541 [==============================] - 2s 888us/step\n"
     ]
    }
   ],
   "source": [
    "# Deep\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_sbert[0]),)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_sbert, y_train, batch_size=batch_size, validation_data=(X_test_sbert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_sbert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_sbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c1369b",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4492725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:19<00:00, 19.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.2335 - accuracy: 0.9046\n",
      "Test loss: 0.23349975049495697\n",
      "Test accuracy: 0.9046489000320435\n",
      "2541/2541 [==============================] - 2s 882us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_bert[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_bert, y_train, batch_size=batch_size, validation_data=(X_test_bert, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_bert, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f028785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905\n",
      "F1 Score: 0.903\n",
      "Precision: 0.914\n",
      "Recall: 0.894\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = [0 if num < 0.5 else 1 for num in predictions]\n",
    "\n",
    "accuracy_nn = accuracy_score(y_test, nn_predictions)\n",
    "precision_nn = precision_score(y_test, nn_predictions)\n",
    "recall_nn = recall_score(y_test, nn_predictions)\n",
    "f1_nn = f1_score(y_test, nn_predictions)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_nn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_nn, 3)}\")\n",
    "print(f\"Precision: {round(precision_nn, 3)}\")\n",
    "print(f\"Recall: {round(recall_nn, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bead16",
   "metadata": {},
   "source": [
    "## RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e91fed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [03:20<00:00, 20.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 3s 1ms/step - loss: 0.1980 - accuracy: 0.9223\n",
      "Test loss: 0.19799984991550446\n",
      "Test accuracy: 0.9222850799560547\n",
      "2541/2541 [==============================] - 2s 886us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(len(X_train_roberta[0]),)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "    model.fit(X_train_roberta, y_train, batch_size=batch_size, validation_data=(X_test_roberta, y_test), verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_roberta, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "predictions = model.predict(X_test_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5162a321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922\n",
      "F1 Score: 0.92\n",
      "Precision: 0.95\n",
      "Recall: 0.892\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = [0 if num < 0.5 else 1 for num in predictions]\n",
    "\n",
    "accuracy_nn = accuracy_score(y_test, nn_predictions)\n",
    "precision_nn = precision_score(y_test, nn_predictions)\n",
    "recall_nn = recall_score(y_test, nn_predictions)\n",
    "f1_nn = f1_score(y_test, nn_predictions)\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_nn, 3)}\")\n",
    "print(f\"F1 Score: {round(f1_nn, 3)}\")\n",
    "print(f\"Precision: {round(precision_nn, 3)}\")\n",
    "print(f\"Recall: {round(recall_nn, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a885df7",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b5b10dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /cluster/home/olavanom/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3945caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f92002e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2293826/2463601894.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_compound'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
      "/tmp/ipykernel_2293826/2463601894.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_positive'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['pos'])\n",
      "/tmp/ipykernel_2293826/2463601894.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_negative'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['neg'])\n"
     ]
    }
   ],
   "source": [
    "df['sentiment_compound'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "df['sentiment_positive'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['pos'])\n",
    "df['sentiment_negative'] = df['review'].apply(lambda x: analyzer.polarity_scores(x)['neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f291e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5933567500024597\n",
      "0.624083749028405\n",
      "0.6437394846365004\n",
      "0.6672840599388018\n",
      "0.6817571356887747\n",
      "\n",
      "0.654527878626878\n",
      "\n",
      "0.7304623316311973\n",
      "0.7385917530033353\n",
      "0.7394870962346389\n",
      "0.7429676200596239\n",
      "0.7185522988675384\n",
      "\n",
      "0.7433562580556293\n"
     ]
    }
   ],
   "source": [
    "def filter_df(n):\n",
    "    return df[((df['positive'] == 1) & (df['sentiment_compound'] > n)) | ((df['positive'] == 0) & (df['sentiment_compound'] < n))]\n",
    "\n",
    "print(len(filter_df(-0.5)) / len(df))\n",
    "print(len(filter_df(-0.4)) / len(df))\n",
    "print(len(filter_df(-0.3)) / len(df))\n",
    "print(len(filter_df(-0.2)) / len(df))\n",
    "print(len(filter_df(-0.1)) / len(df))\n",
    "print(\"\")\n",
    "print(len(filter_df(0)) / len(df))\n",
    "print(\"\")\n",
    "print(len(filter_df(0.1)) / len(df))\n",
    "print(len(filter_df(0.2)) / len(df))\n",
    "print(len(filter_df(0.3)) / len(df))\n",
    "print(len(filter_df(0.4)) / len(df))\n",
    "print(len(filter_df(0.5)) / len(df))\n",
    "print(\"\")\n",
    "print(len(filter_df(0.42)) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62195353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6539793579109969\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[((df['positive'] == 1) & (df['sentiment_positive'] > df['sentiment_negative'])) | ((df['positive'] == 0) & (df['sentiment_negative'] > df['sentiment_positive']))]\n",
    "\n",
    "print(len(filtered_df)/len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
